# Reranker重排序模型介绍

上次我们讲了Embedding嵌入模型，它负责把我们本地的文档数据向量化后存储到我们本的向量数据库中。

今天我们来介绍Reranker重排序模型，在之前还是让我们先回顾一下RAG系统的知识。

![](https://p3-sign.toutiaoimg.com/tos-cn-i-axegupay5k/1f50f9926d494f7f8e405639acbe06f7~tplv-tt-origin-web:gif.jpeg?_iz=58558&from=article.pc_detail&lk3s=953192f4&x-expires=1743231978&x-signature=vETxpgoR3uuTlzZe0u%2FITOAZ0Cg%3D)

## 1. RAG 系统概述

检索增强生成（Retrieval-Augmented Generation, RAG）是一种结合大型语言模型（LLM）与外部知识库的技术。

目的是为了解决LLM的“幻觉”问题、知识更新滞后及私域数据利用难题。

其核心流程分为三阶段：

- 检索→重排序→生成，其中 Embedding 嵌入模型与 Reranker 重排序模型是两大关键技术。

Reranker模型就像RAG知识库的“质检员”，是知识库的重要组成部分。

## 2. 核心一：Embedding 模型

### 2.1 作用与原理

Embedding 模型将文本映射为向量，用于衡量语义相似性。其核心价值在于语义理解：捕捉文本深层语义关系，支持跨语言、跨粒度检索。

### 2.2 主流模型对比


| 模型   | 特点                                      | 适用场景                 |
| ------ | ----------------------------------------- | ------------------------ |
| BGE-M3 | 支持100+语言、多粒度输入（最长8k tokens） | 多语言、长文档、混合检索 |
| Jina   | 实现长文本处理                            | 双语场景、代码检索       |
| M3E    | 中英双语优化，支持指令化Embedding生成     | 中文为主、轻量化需求     |

## 3. 核心二：Reranker 模型

### 3.1 Reranker本质

Reranker是知识库的"智能质检员"，假设你在图书馆找书，先用关键词检索到100本书，但需要找出最相关的3本才行。

图书管理员（Reranker）会综合评估书籍内容、出版时间、作者权威性等维度进行二次筛选。

将检索到的候选文档（如100条）按照与问题的相关度重新排序，把最匹配的结果提升到Top位置。

### 3.2 排序的关键维度

#### 3.2.1. 语义相关性

- 用户问题："糖尿病患者的饮食禁忌有哪些？"
  - 候选文档1：详细列举12种糖尿病饮食禁忌（相关度高）
  - 候选文档2：讲解胰岛素注射方法（相关度低）

#### 3.2.2. 时效性权重

- 文档A：2023年《中国糖尿病防治指南》（权重+20%）
- 文档B：2010年某医院内部资料（权重-30%）

#### 3.2.3. 多样性控制

避免返回3篇都讲"糖分控制"的文章，保留1篇"运动管理"的补充内容。

### 3.3 排序面临的挑战

![](https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/712aeb0ccd864bb7a193cc0320000683~tplv-tt-origin-web:gif.jpeg?_iz=58558&from=article.pc_detail&lk3s=953192f4&x-expires=1743231978&x-signature=D%2B1ezLp9yK3SLSY4StM7YpBlTfk%3D)

#### 3.3.1. 长尾问题

- 问题："AI agent怎么学？"
  - 检索结果1：前9篇都是各种模型的内容（未命中核心需求），只有1篇介绍ai agent入门书籍的。（命中）
  - 检索结果2：前8篇都是各种模型的内容（未命中核心需求），只有2篇介绍ai agent入门书籍的。（命中）

#### 3.3.2. 语义鸿沟

- 用户问："电脑蓝屏怎么办"
  - 文档写："Windows系统内核崩溃处理"（语义相关但字面不匹配）

#### 3.3.3. 多语言混合

知识库包含中英文文献，用户中文提问需匹配英文论文中的关键结论。

#### 3.3.4. 计算效率

在10万篇文档库中，短时间内完成1000篇候选的重新排序，需要不少的算力。

### 3.4 典型排序算法演进

#### 3.4.1. 传统方法：BM25

BM25 是一种用来评价搜索词和文档之间相关性的算法，它是一种基于概率检索模型提出的算法。特别是在处理长文档和短查询时表现出色，它根据查询词在文档中的出现频率、文档的长度等因素来计算文档与查询的相关性得分。

**示例文档集和查询**

```python
docs = [
    ["apple", "banana", "cherry"],
    ["apple", "date"],
    ["banana", "elderberry"],
    ["apple", "banana", "banana", "fig"]
]

# 查询
query = ["apple", "banana"]
```

- 文档 1 (apple banana cherry): 得分约为 1.34
- 文档 2 (apple date): 得分约为 0.67
- 文档 3 (banana elderberry): 得分约为 0.67
- 文档 4 (apple banana banana fig): 得分约为 1.71

#### 3.4.2. 深度语义模型：Cross-Encoder

Cross-Encoder（交叉编码器）是一种用于计算文本对之间相关性得分的模型架构，在信息检索、自然语言推理、问答系统等多个自然语言处理任务中都有广泛应用。Cross-Encoder 直接将文本对作为输入，通过一个编码器统一处理，能够更有效地捕捉文本对之间的交互信息，从而得到更准确的相关性得分。

**文档集合**

```python
docs = [
    "苹果是一种常见的水果，富含维生素。",
    "香蕉是热带水果，味道香甜。",
    "橙子具有丰富的维生素 C。",
    "葡萄可以酿酒，口感酸甜。"
]

# 查询
query = "哪种水果富含维生素"
```

- 文档 1 (苹果是一种常见的水果，富含维生素。): 得分约为 2.50
- 文档 2 (香蕉是热带水果，味道香甜。): 得分约为 0.30
- 文档 3 (橙子具有丰富的维生素 C。): 得分约为 2.80
- 文档 4 (葡萄可以酿酒，口感酸甜。): 得分约为 0.20

#### 3.4.3. 最新进展：Col-BERT

Col-BERT是一种用于高效信息检索的模型，它结合了基于表示和基于交互的检索方法的优点。与传统的基于词袋模型或基于表示的检索方法不同，Col-BERT 在细粒度的词级别上对查询和文档进行交互，从而能够更准确地捕捉语义相关性。

**文档集合**

```python
docs = [
    "苹果是一种常见的水果，富含维生素。",
    "香蕉是热带水果，味道香甜。",
    "橙子具有丰富的维生素 C。",
    "葡萄可以酿酒，口感酸甜。"
]

# 查询
query = "哪种水果富含维生素？"
```

- 文档 1 (苹果是一种常见的水果，富含维生素。): 得分约为 35.68
- 文档 2 (香蕉是热带水果，味道香甜。): 得分约为 22.34
- 文档 3 (橙子具有丰富的维生素 C。): 得分约为 38.21
- 文档 4 (葡萄可以酿酒，口感酸甜。): 得分约为 20.12

### 3.5 主流模型选型


| 模型          | 特点                         | 性能优势                   |
| ------------- | ---------------------------- | -------------------------- |
| BGE ReRanker  | 支持多语言                   | 多语言场景、高精度需求     |
| Jina Reranker | 8k上下文支持                 | 长文本排序、低延迟场景     |
| BCE-Reranker  | 网易有道开源，中英跨语言优化 | 中英混合场景、高召回率需求 |

## 4. 完整排序流程示例

用户问题："美联储加息对A股的影响"

初步检索（Retriever）：
返回50篇文档：

- 10篇关于美国货币政策
- 15篇A股市场分析
- 20篇历史加息案例
- 5篇无关内容

Reranker工作流：

```python
for 文档 in 50篇:
    计算语义相关性（BERT模型）→ 得分0.6-0.95
    叠加时效性权重（2023年文档×1.2）
    扣除低权威惩罚（自媒体文章×0.7）
    最终得分 = 语义分×时效权重×权威系数
```

排序后Top3：

1. 《2023年美联储政策与新兴市场联动分析》（0.94）
2. 《跨境资本流动对A股的影响机制》（0.91）
3. 《历史六轮加息周期中的板块表现》（0.89）

今天的讲解就这些内容了，Reranker就像知识库的"智能质检员"，本地知识库检索的最后一道防线，通过多维度考量让结果排序更符合真实需求。
